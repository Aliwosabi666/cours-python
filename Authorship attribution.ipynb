{
 "metadata": {
  "name": "Authorship attribution"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Chapter 5: Building NLP applications"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the last chapter we made some tools to prepare corpora for further processing. To be able to tokenise a text is nice, but from a humanities perspective not very interesting. So, what are we going to do with it? In this chapter, you'll implement two major applications that build upon the tools you developed. The first will be a program that scores each text in a corpus according to its Automatic Readability Index. In the second application we will build a system that can predict who wrote a certain text. Again, we'll need to cover a lot of ground. So, let's get started!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Automatic Readability Index"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Automatic Readability Index is a readability test designed to gauge the understandability of a text. The formula for calculating the Automated Readability Index is as follows:\n",
      "\n",
      "$$ 4.71 \\cdot \\frac{nchars}{nwords} + 0.5 \\cdot \\frac{nwords}{nsentences} - 21.43 $$\n",
      "\n",
      "Let's apply some wishful thinking. If we have all the information needed to compute this formula, we can start with writing a function that does it for us. Let's do so."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "--------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write a function `AutomaticReadabilityIndex` that takes three arguments `n_chars`, `n_words` and `n-sents` and returns the ARI given those arguments."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def AutomaticReadabilityIndex(n_chars, n_words, n_sents):\n",
      "    # insert your code here\n",
      "\n",
      "print('%.3f' % AutomaticReadabilityIndex(300, 40, 10) == '15.895')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we need to write some code to obtain the numbers we so wishfully assumed to have. We will use the code we wrote in earlier chapters to read and tokenise texts. We stored all the functions we wrote for our corpus reader in `preprocess.py`. We only need the function `readcorpus` and import it here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from preprocess import readcorpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Remember that the function readcorpus returns a generator of `(filename, sentences)` tuples. Sentences are represented by lists of strings. Let's write a function `extract_counts` that takes a list of sentences as input and returns the number of characters, the number of words and the number of sentences as a tuple."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "----------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write the function `extract_counts`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_counts(sentences):\n",
      "    # insert your code here\n",
      "    \n",
      "print(extract_counts(\n",
      "    [[\"This\", \"was\", \"rather\", \"easy\", \".\"], \n",
      "     [\"Please\", \"give\", \"me\", \"something\", \"more\", \"challenging\"]]) == (54, 11, 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Well done! We're almost done. We could use our two functions to compute the ARI for a given text as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentences = [[\"This\", \"was\", \"rather\", \"easy\", \".\"], \n",
      "             [\"Please\", \"give\", \"me\", \"something\", \"more\", \"challenging\"]]\n",
      "\n",
      "n_chars, n_words, n_sents = extract_counts(sentences)\n",
      "\n",
      "print(\"%.3f\" % AutomaticReadabilityIndex(n_chars, n_words, n_sents) == \"4.442\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, it would be nice to have a little more abstraction."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write the function `compute_ARI` that takes a argument a list of sentences (represented by lists of words) and returns the Automatic Readability Index for that input."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_ARI(sentences):\n",
      "    # insert your code here\n",
      "    \n",
      "print(\"%.3f\" % compute_ARI(sentences) == \"4.442\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "expected an indented block (<ipython-input-1-8b6a023ee164>, line 4)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "--------------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Authorship attribution\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this section you will implement the core of a authorship attribution application. You won't build a full stand-alone application, but rather focus on the core functions for classifying new texts for their authors.\n",
      "\n",
      "The core of our application will be a naive bayes classifier. Following good programming principles, we will try to make this classifier as generic as possible. This allows us to use the classifier in other contexts than authorship attribution, such as text classification and classification in general."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The naive bayes classifier is a probabilistic classifier that given a set of features tries to find the class with the highest probability. It is based on applying Bayes' theorem and is called naive because of its strong independence assumption between features. This means that the absence or presence of each feature is assumed to be independent of each other. We compute the posterior probability of a class as the joint probability of all features given that class:\n",
      "\n",
      "$$ P(y|x_1,\\ldots,x_n) \\propto P(y) \\prod^n_{i=1} P(x_i|y)$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Classification is based on the *maximum a posteriori* or MAP descision rule which simply picks the class (or author in our case) that is most probable:\n",
      "\n",
      "$$ classify(x_1, \\ldots, x_n) = \\arg\\max_y P(y) \\prod^n_{i=1} P(x_i|y) $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The main function we will implement has a simple job: take a text as an argument and classify it as being written by one of the authors. Let's again apply some wishful thinking and implement the function as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_author(text, training_data):\n",
      "    \"Predict who wrote this text.\"\n",
      "    return classify(score(extract_features(text), training_data))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This function takes two arguments: the text to classify and the training data against we want to classify the text. The function is basically an abstraction layer on top of `classify`,  `extract_features` and `score`. `classify` is a simple function that takes a dictionary of {$author_i$:  $P(author_i|text)$} and returns the author that is most probable. Let's implement this function:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "-----------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Implement the function `classify`. It takes one argument, `scores` which is a dictionary with authors as keys and the probability of an author as value. Return the author with maximum probability. (Tip: use the built in function `max`, see [the documentation](http://docs.python.org/2/library/functions.html#max))"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = {\"Hermans\": 0.15, \"Voskuil\": 0.55, \"Reve\": 0.2, \"Mulisch\": 0.18, \"Claus\": 0.02}\n",
      "\n",
      "def classify(scores):\n",
      "    # insert your code here\n",
      "    \n",
      "print(classify(scores) == \"Voskuil\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The function `extract_features` is rather straightforward as well. We'll build this function on top of the functions we defined in the previous chapters. For the moment we will assume that our model is a bag-of-words (BOW) model where the only features are individual words. For each word we need to know how often it occurs with a particular author. We'll implement this as a nested dictionary `{word: {author: count}}`."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Think about why the `word -> author -> count` structure is a better choice than `author -> word -> count`. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "--------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# database = {word : {author: count, author: count}}\n",
      "database = defaultdict(lambda: defaultdict(int))\n",
      "\n",
      "def get_author(filename):\n",
      "    return filename.split('-')[0]\n",
      "\n",
      "def add_file_to_database(text, author):\n",
      "    \"Add a text (which is a list of sentences) to the database.\"\n",
      "    tokens = tokenise(text)\n",
      "    sentences = splitsentences(tokens)\n",
      "    for sentence in sentences:\n",
      "        for word in sentence:\n",
      "            database[author][word] += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def prior(klass, database):\n",
      "    return log(sum(1 for label in database if label == klass) / len(database))\n",
      "\n",
      "def classify(document, database):\n",
      "    scores = defaultdict(float)\n",
      "    # get the number of unique features used in the training corpus\n",
      "    n_features = len(set(feature for klass, features in database.items() \n",
      "                                 for feature in features))\n",
      "    for klass in database:\n",
      "        # class prior smoothing.\n",
      "        scores[klass] += prior(klass, database)\n",
      "        # store for efficiency \n",
      "        klass_feature_sum = sum(database[klass].values())\n",
      "        for feature in document:\n",
      "            scores[klass] += log((database[klass][feature] + 1.0) / \n",
      "                                 (klass_feature_sum + n_features))\n",
      "    return max(scores, key=scores.__getitem__)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"styles/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        width:800px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: \"Charis SIL\", Palatino, serif;\n",
        "    }\n",
        "    h4{\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "    div.text_cell_render{\n",
        "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 145%;\n",
        "        font-size: 120%;\n",
        "        width:800px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
        "    }\n",
        "    .prompt{\n",
        "        display: None;\n",
        "    }\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 16pt;\n",
        "        color: #4057A1;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    \n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }\n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>"
       ],
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "<IPython.core.display.HTML at 0x104b89590>"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}