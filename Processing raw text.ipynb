{
 "metadata": {
  "name": "Processing raw text"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Chapter 4: Processing raw text"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Sentence Splitting"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write a function `splitsentences` that performs a very simple sentence splitting when passed a list of tokens. Each sentence should be represented as a list of tokens, so the function as a whole returns a list of lists of tokens.\n",
      "\n",
      "A tuple of end-of-sentence markers is given. You may assume that any occurrence of an end-of-sentence marker marks the end of a sentence. In reality, this is more ambiguous of course, consider for example the use of periods as end-of-sentence marker as well as in abbreviations and initials!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "endofsentencemarkers = ('.','!','?')\n",
      "\n",
      "def splitsentences(tokens):\n",
      "    #<write your code here>\n",
      "\n",
      "#these tests should return True if your code is correct\n",
      "print(splitsentences( ['This','is','one','sentence','.','This','is','the','second','.']) == \n",
      " [ ['This','is','one','sentence','.'],['This','is','the','second','.'] ])\n",
      "print(splitsentences( ['Hello', 'world','!','I','know','Python','!']) == \n",
      "[ ['Hello','world','!'],['I','know','Python','!'] ])\n",
      "    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "expected an indented block (<ipython-input-8-cf2c8809a40a>, line 7)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Bonus exercise"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Adapt the sentence splitter to also make it work when end-of-sentence markers are found in repetition, such as in ellipsis (...). A sentence should only be split at the last of such markers."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Simple Tokenisation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tokenisation is a very common pre-processing stage for many NLP tasks. We are going to write a simple tokeniser which detaches any punctuation attached to words and produces a list of tokens. Write a function `tokenise(text)` which takes a string as parameter and returns a list of tokens. Punctuation characters should become separate tokens, whitespace and newlines never become tokens."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tokenise(text):\n",
      "    #<write your code here>\n",
      "\n",
      "#The following tests should all return True if your code is correct \n",
      "print(tokenise(\"This is a test\") == [\"This\",\"is\",\"a\",\"test\"])\n",
      "print(tokenise(\"To be or not to be, that is the question!\") == [\"To\",\"be\",\"or\",\"not\",\"to\",\"be\",\",\",\"that\",\"is\",\"the\",\"question\",\"!\"])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "expected an indented block (<ipython-input-1-c7c832659930>, line 5)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now combine this with the sentence splitter we wrote above: "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "quote = \"To be or not to be, that is the question; Whether 'tis nobler in the mind to suffer the slings and arrows of outrageous fortune, or to take arms against a sea of troubles, and by opposing, end them.\"\n",
      "sentences = splitsentences(tokenise(quote))\n",
      "print(sentences)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Extracting n-grams"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "N-grams are very common in NLP applications. An n-gram is a token sequence of length n. We are going to write a function `getngrams(tokens,n)`, where the first parameter is a longer sequence of tokens (such as a sentence), to extract from. The last argument specifies the size of the n-gram we want to extract. The goal is to extract all n-grams present in the list of tokens. Each n-gram should be either a list or tuple of length n.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getngrams(tokens,n):\n",
      "    #<insert your code here>\n",
      "    \n",
      "quote = ['To','be','or','not','to','be']\n",
      "print(getngrams(quote) ==  [['to','be','or'],['be','or','not'],['or','not','to'],['not','to','be']])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Computing a Frequency List"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this exercise we are going to create a frequency list given a set of sentences, again in which each sentence consists of a list of tokens. We are thus going to kind how many times each type of word occurs in the text."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What data structure would be most suitable for a frequency list? A dictionary! They keys will be words, and the value will be the number of times the word occurs."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For this purpose however, we are going to introduce a new kind of dictionary rather than the built-in one. Recall the following:\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "freqlist = {'to':2,'be':2,'or':1,'not':1}\n",
      "print(freqlist['to'])\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(freqlist['was'])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "'was'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-4-e69790e0aefa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreqlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'was'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mKeyError\u001b[0m: 'was'"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Specifying a non-existant key on a dictionary will give a KeyError. We are going to use a special dictionary called a `defaultdict` which circumvents this problem and returns a default value when a key does not exist. In this situation we would like a default value of zero (an integer). Create a `defaultdict` for integers as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "freqlist = defaultdict(int)\n",
      "print(freqlist['was'])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Except for this behaviour, the defaultdict behaves just like a normal dictionary. Now write a function `makefrequencylist(sentences)` that creates a frequency list for all passed sentences (each consisting of a list of tokens). In computing the frequency list, use lower-case only, thus removing any case-sensitivity."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "def makefrequencylist(sentences):\n",
      "    freqlist = defaultdict(int)\n",
      "    #<write your code here>\n",
      "    return freqlist\n",
      "\n",
      "sentences = [['To','be','or','not','to','be'],['that','is','the','question']]\n",
      "freqlist = makefrequencylist(sentences)\n",
      "\n",
      "#These tests should all return True if your implementation is correction\n",
      "print(freqlist['be'] == 2)\n",
      "print(freqlist['or'] == 1)\n",
      "print(freqlist['to'] == 2) #only works if not case-sensitive\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "False\n",
        "False\n",
        "False\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Bonus exercise"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Rather than creating a frequency list for words, we can also create a frequency list for n-grams. Write a new version of makefrequencylist2(sentences, n) which makes a frequency list using n-grams of the specified size. Reuse the getngrams() function you wrote earlier. Make sure to use tuples instead of lists as dictionary key; only immutables like tuples can be dictionary keys, so lists won't work. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "def makefrequencylist2(sentences, n):\n",
      "    freqlist = defaultdict(int)\n",
      "    #<write your code here>\n",
      "    return freqlist\n",
      "\n",
      "sentences = [['To','be','or','not','to','be'],['that','is','the','question']]\n",
      "freqlist = makefrequencylist2(sentences, 2)\n",
      "\n",
      "#These tests should all return True if your implementation is correction\n",
      "print(freqlist[('to','be')] == 2)\n",
      "print(freqlist[('or','not')] == 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Finding files and reading a corpus"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"styles/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        width:800px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: \"Charis SIL\", Palatino, serif;\n",
        "    }\n",
        "    h4{\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "    div.text_cell_render{\n",
        "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 145%;\n",
        "        font-size: 120%;\n",
        "        width:800px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
        "    }\n",
        "    .prompt{\n",
        "        display: None;\n",
        "    }\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 16pt;\n",
        "        color: #4057A1;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    \n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }\n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>"
       ],
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x108cb9710>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}