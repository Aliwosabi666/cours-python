{
 "metadata": {
  "name": "Authorship attribution"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Chapter 5: Building NLP applications"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the last chapter we made some tools to prepare corpora for further processing. To be able to tokenise a text is nice, but from a humanties perspective not very interesting. So, what are we going to do with it? In this chapter, you'll implement two major applications that build upon the tools you developed. The first will be a program that scores each text in a corpus according to its Automatic Readability Index. In the second application we will build a system that can predict who wrote a certain text. Again, we'll need to cover a lot of ground. So, let's get started!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Automatic Readability Index"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Automatic Readability Index is a readability test designed to gauge the understandability of a text. The formula for calculating the Automated Readability Index is as follows:\n",
      "\n",
      "$$ 4.71 \\cdot \\frac{nchars}{nwords} + 0.5 \\cdot \\frac{nwords}{nsentences} - 21.43 $$\n",
      "\n",
      "Let's apply some wishful thinking. If we have all the information needed to compute this formula, we can write a function that does it for us. Let's do so."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "--------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write a function `AutomaticReadabilityIndex` that takes three arguments `n_chars`, `n_words` and `n-sents` and returns the ARI given those arguments."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def AutomaticReadabilityIndex(n_chars, n_words, n_sents):\n",
      "    # insert your code here\n",
      "\n",
      "print('%.3f' % AutomaticReadabilityIndex(300, 40, 10) == '15.895')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we need to write some code to obtain the numbers we so wishfully assumed to have. We will use the code we wrote in earlier chapters to read and tokenise texts. We stored all the functions we wrote for our corpus reader in `preprocess.py`. We only need the function `readcorpus` and import it here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from preprocess import readcorpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Remember that the function readcorpus returns a generator of `(filename, sentences)` tuples. Sentences are represented by lists of strings. Let's write a function `extract_counts` that takes a list of sentences as input and returns the number of characters, the number of words and the number of sentences as a tuple."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "----------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write the function `extract_counts`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_counts(sentences):\n",
      "    # insert your code here\n",
      "    \n",
      "print(extract_counts(\n",
      "    [[\"This\", \"was\", \"rather\", \"easy\", \".\"], \n",
      "     [\"Please\", \"give\", \"me\", \"something\", \"more\", \"challenging\"]]) == (54, 11, 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Well done! We're almost done. We could use our two functions to compute the ARI for a given text as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentences = [[\"This\", \"was\", \"rather\", \"easy\", \".\"], \n",
      "             [\"Please\", \"give\", \"me\", \"something\", \"more\", \"challenging\"]]\n",
      "\n",
      "n_chars, n_words, n_sents = extract_counts(sentences)\n",
      "\n",
      "print(\"%.3f\" % AutomaticReadabilityIndex(n_chars, n_words, n_sents) == \"4.442\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, it would be nice to have a little more abstraction."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write the function `compute_ARI` that takes a argument a list of sentences (represented by lists of words) and returns the Automatic Readability Index for that input."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_ARI(sentences):\n",
      "    # insert your code here\n",
      "    \n",
      "print(\"%.3f\" % compute_ARI(sentences) == \"4.442\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "expected an indented block (<ipython-input-1-8b6a023ee164>, line 4)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "--------------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Authorship attribution\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this section you will implement the core of a authorship attribution application. You won't a full stand-alone application, but rather focus on the core functions for classifying new texts for their authors.\n",
      "\n",
      "The core of our application will be a naive bayes classifier. Following good programming principles, we will try to make this classifier as generic as possible. This allows us to use the classifier in other contexts than authorship attribution, such as text classification and classification in general.\n",
      "\n",
      "The naive bayes classifier is a probabilistic classifier that given a set of features tries to find the class with the highest probability. It is based on applying Bayes' theorem and is called naive because of its strong independence assumption between features. This means that the absence or presence of each feature is assumed to be independent of each other. We compute the posterior probability of a class as the joint probability of all features given that class:\n",
      "\n",
      "$$ P(y|x_1,\\ldots,x_n) \\propto P(y) \\prod^n_{i=1} P(x_i|y)$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Classification is based on the *maximum a posteriori* or MAP descision rule which simply picks the class (or author in our case) that is most probable:\n",
      "\n",
      "$$ classify(x_1, \\ldots, x_n) = \\arg\\max_y P(y) \\prod^n_{i=1} P(x_i|y) $$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"styles/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        width:800px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: \"Charis SIL\", Palatino, serif;\n",
        "    }\n",
        "    h4{\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "    div.text_cell_render{\n",
        "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 145%;\n",
        "        font-size: 120%;\n",
        "        width:800px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
        "    }\n",
        "    .prompt{\n",
        "        display: None;\n",
        "    }\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 16pt;\n",
        "        color: #4057A1;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    \n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }\n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>"
       ],
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "<IPython.core.display.HTML at 0x104b89590>"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}