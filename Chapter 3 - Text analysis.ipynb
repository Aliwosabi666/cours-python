{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Chapter 3: Text Analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "-- *A Python Course for the Humanities by Folgert Karsdorp and Maarten van Gompel*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this chapter we will introduce you to the task of text analysis in Python. You will learn how to read an entire corpus into Python, clean it and how to perform certain data analyses on those texts. We will also briefly introduce you to using Python's plotting library matplotlib, with which you can visualize your data.\n",
      "\n",
      "Before we delve into the main subject of this chapter, text analysis, we will first write a couple of utility functions that build upon the things you learnt in the previous chapter. Often we don't work with a single text file stored at our computer, but with multiple text files or entire corpora. We would like to have a way to load a corpus into Python.\n",
      "\n",
      "Remember how to read files? We write a small utility function `read_file(filename)` that reads the specified file and simply returns all contents as a single string."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def read_file(filename):\n",
      "    \"Read the contents of FILENAME and return as a string.\"\n",
      "    infile = open(filename) \n",
      "    contents = infile.read()\n",
      "    infile.close()\n",
      "    return contents"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, in the directory `data/gutenberg/training` we have a corpus consisting of multiple \\*.txt. This corpus is a collection of English novels which we downloaded for you from the [Gutenberg](http://www.gutenberg.org) project. We want to iterate over all these files. You can do this with the `listdir` function from the `os` module. We can import this function using the following:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os import listdir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After that, the `listdir` function is available to use. We will see many other import statements later on in this chapter. Now, consider the following function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def list_textfiles(directory):\n",
      "    \"Return a list of filenames ending in '.txt' in DIRECTORY.\"\n",
      "    textfiles = []\n",
      "    for filename in listdir(directory):\n",
      "        if filename.endswith(\".txt\"):\n",
      "            textfiles.append(directory + \"/\" + filename)\n",
      "    return textfiles"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The function `listdir` takes as argument the name of a directory and lists all filenames in that directory. We iterate over this list and append each filename that ends with the extension, \".txt\" to a new list of `textfiles`. Using the `list_textfiles` function, the following code will read all text files in the directory `data/arabian_nights` and outputs the length (in characters) of each:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for filepath in list_textfiles(\"data/gutenberg/training\"):\n",
      "    text = read_file(filepath)\n",
      "    print(filepath, \"has\", len(text), \"characters\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "data/gutenberg/training/austen-emma.txt has 887071 characters\n",
        "data/gutenberg/training/austen-pride.txt has 684765 characters\n",
        "data/gutenberg/training/austen-sense.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has 673022 characters\n",
        "data/gutenberg/training/blake-poems.txt has 38153 characters\n",
        "data/gutenberg/training/blake-songs.txt has 32223 characters\n",
        "data/gutenberg/training/bryant-stories.txt has 243901 characters\n",
        "data/gutenberg/training/burgess-busterbrown.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has 82992 characters\n",
        "data/gutenberg/training/carroll-alice.txt has 144395 characters\n",
        "data/gutenberg/training/chesterton-ball.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has 457450 characters\n",
        "data/gutenberg/training/chesterton-thursday.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has 320525 characters\n",
        "data/gutenberg/training/edgeworth-parents.txt has 916861 characters\n",
        "data/gutenberg/training/melville-piazza.txt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " has 467970 characters\n",
        "data/gutenberg/training/milton-paradise.txt has 468220 characters\n",
        "data/gutenberg/training/shakespeare-caesar.txt has 112310 characters\n",
        "data/gutenberg/training/shakespeare-hamlet.txt has 162881 characters\n",
        "data/gutenberg/training/whitman-leaves.txt has 711215 characters\n",
        "data/gutenberg/training/whitman-patriotic.txt has 174241 characters\n",
        "data/gutenberg/training/whitman-poems.txt has 395130 characters\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Sentence tokenization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the previous chapter we wrote a function to tokenize or split a text string into a list of tokens. However, using this function we lose information about where sentences end and start in the text. We will develop a function `split_sentences` that performs a very simple sentence splitting when passed text string. Each sentence will be represented as a new string, so the function as a whole returns a list of sentence strings. We assume that any occurrence of either `.` or `!` or `?` marks the end of a sentence. In reality, this is more ambiguous of course, consider for example the use of periods as end-of-sentence marker as well as in abbreviations and initials!\n",
      "\n",
      "How should we tackle this problem? Have a look at the following picture:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "![caption](files/indexing.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first sentence *Hello there!* spans from 0 to 11. The second sentence from 13 to 26. If we kind come up with a way to extract those indexes, we could slice the text using those indexes into separate sentences. First we define a utility function `end_of_sentence` that takes as argument a character and returns True if it is an end-of-sentence marker, otherwise it returns False. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write the function `end_of_sentence_marker` below:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def end_of_sentence_marker(character):\n",
      "    # insert your code here\n",
      "\n",
      "# these tests should return True if your code is correct\n",
      "print(end_of_sentence_marker(\"?\") == True)\n",
      "print(end_of_sentence_marker(\"a\") == False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "An important function we will use is the built in `enumerate`. `enumerate` takes as argument any iterable (a string a list etc.). Let's see it in action:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for element in enumerate(\"Python\"):\n",
      "    print(element)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see, enumerate allows you to iterate over an iterable and for each element in that iterable, it gives you its corresponding index. A slightly more convenient way of iterating over `enumerate` is the following:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, character in enumerate(\"Python\"):\n",
      "    print(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This way, we have easy access to both the index and the original item in the iterable. Now we know enough to write our `split_sentences` function. We walk you through it, step by step, but first try to read the function and think about what is possible does at each step:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def split_sentences(text):\n",
      "    \"Split a text string into a list of sentences.\"\n",
      "    sentences = []\n",
      "    start = 0\n",
      "    for end, character in enumerate(text):\n",
      "        if end_of_sentence_marker(character):\n",
      "            sentence = text[start: end + 1]\n",
      "            sentences.append(sentence)\n",
      "            start = end + 1\n",
      "    return sentences"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The function `split_sentences` takes as argument a text represented by a simple string. Within the function we define a variable `sentences` in which we will store the individual sentences. We need to extract both the start position and end position of each sentence. We know that the first sentence will always start at position 0. Therefore we define a variable start and set it to zero.\n",
      "\n",
      "Next we will use `enumerate` to loop over all individual characters in the text. Remember that enumerate returns pairs of indexes and their corresponding elements (here characters) in some iterable. For each character we check whether it is an end-of-sentence marker. If it is, the variable `end` marks the position in `text` where a sentence ends. We can now slice the text from the starting position to the end position and obtain our sentence. Notice that we add 1 to the end position. Why would that be? This is because as you might remember from the first chapter, slices are non-inclusive, so `text[start:end]` would return the text starting at `start` and ending 1 index before `end`. Since we have reached the end of a sentence, we know that the next sentence will start at least 1 position later than our last end point. Therefore, we update the start variable to `end + 1`. Let's see if our function works as promised:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(split_sentences(\"This is a sentence. Should we seperate it from this one?\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It does! "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To conclude this section, you will write a wrapper function `tokenize`, that takes as input a text represented by a string and tokenizes this string into sentences. After that, we clean each sentence, by lowercasing all words and removing punctuation. The final step is to tokenize each sentence into a list of words. The file `preprocessing.py` contains a function called `clean_text` which removes all punctuation from a text turns all characters to lowercase. We import that function using the following line:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from preprocessing import clean_text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tokenize(text):\n",
      "    \"\"\"Transform TEXT into a list of sentences. Lowercase \n",
      "    each sentence and remove all punctuation. Finally split each\n",
      "    sentence into a list of words.\"\"\"\n",
      "    # insert your code here\n",
      "    \n",
      "# these tests should return True if your code is correct\n",
      "print(tokenize(\"This is a sentence. So, what!\") == \n",
      "      [[\"this\", \"is\", \"a\", \"sentence\"], [\"so\", \"what\"]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "General Text Statistics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> When the next night came, Dinarazad said to her sister Shahrazad: \u2018In God\u2019s name, sister, if you are not asleep, then tell us one of your stories!\u2019 Shahrazad answered: \u2018With great pleasure! I have heard tell, honoured King, that\u2026\u2019"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Alf Laylah Wa Laylah*, *the Stories of One Thousand and One Nights* is a collection of folk tales, collected over many centuries by various authors, translators, and scholars across West, Central and South Asia and North Africa, forms a huge narrative wheel with an overarching plot, created by the frame story of Shahrazad.\n",
      "\n",
      "The stories begin with the tale of king Shahryar and his brother, who, both deceived by their respective Sultanas, leave their kingdom, only to return when they have found someone who \u2014 in their view \u2014 was wronged even more. On their journey the two brothers encounter a huge jinn who carries a glass box containing a beautiful young woman. The two brothers hide as quickly as they can in a tree. The jinn lays his head on the girl\u2019s lap and as soon as he is asleep, the girl demands the two kings to make love to her or else she will wake her \u2018husband\u2019. They reluctantly give in and the brothers soon discover that the girl has already betrayed the jinn ninety-eight times before. This exemplar of lust and treachery strengthens the Sultan\u2019s opinion that all women are wicked and not to be trusted.\n",
      "\n",
      "When king Shahryar returns home, his wrath against women has grown to an unprecedented level. To temper his anger, each night the king sleeps with a virgin only to execute her the next morning. network 'images' In order to make an end to this cruelty and save womanhood from a \"virgin scarcity\", Sharazad offers herself as the next king\u2019s bride. On the first night, Sharazad begins to tell the king a story, but she does not end it. The king\u2019s curiosity to know how the story ends, prevents him from executing Shahrazad. The next night Shahrazad finishes her story, and begins a new one. The king, eager to know the ending of this tale as well, postpones her execution once more. Using this strategy for One Thousand and One Nights in a labyrinth of stories-within-stories-within-stories, Shahrazad attempts to gradually move the king\u2019s cynical stance against women towards a politics of love and justice (see Marina Warner\u2019s Stranger Magic (2013)).\n",
      "\n",
      "The first European version of the Nights was translated into French by Antoine Galland. Many translations (in different languages) followed, such as the (heavily criticized) English translation by Sir Richard Francis Burton entitled The Book of the Thousand and a Night (1885). This version is freely available from the Gutenberg project (see [here](http://www.gutenberg.org)), and will be the one we will explore here."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the directory `data/arabian_nights` you will find 999 files. This is because in Burton's translation some nights are missing. The name of the file represents the corresponding night of storytelling in *Alf Laylah Wa Laylah*. Go have a look. Use the tokenize function and the corpus reading function we have defined above and tokenize and clean each night. Store the result in the variable named `corpus`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# insert your code here\n",
      "corpus = [tokenize(read_file(night)) for night in list_textfiles(\"data/arabian_nights\")]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Great job! You now should have a corpus containing 999 texts. It is always important to check whether our code actually produces the desired results. Let's check whether we indeed have 999 texts:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(len(corpus))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "999\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OK, that seems to be correct. It would be convenient to have the corpus in chronological order. The question is whether the function `list_textfiles` can assure us that it is. Let's have a look the first 20 files returned by `list_textfiles`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "list_textfiles(\"data/arabian_nights\")[:20]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "['data/arabian_nights/1.txt',\n",
        " 'data/arabian_nights/10.txt',\n",
        " 'data/arabian_nights/100.txt',\n",
        " 'data/arabian_nights/1000.txt',\n",
        " 'data/arabian_nights/1001.txt',\n",
        " 'data/arabian_nights/101.txt',\n",
        " 'data/arabian_nights/102.txt',\n",
        " 'data/arabian_nights/103.txt',\n",
        " 'data/arabian_nights/104.txt',\n",
        " 'data/arabian_nights/105.txt',\n",
        " 'data/arabian_nights/106.txt',\n",
        " 'data/arabian_nights/107.txt',\n",
        " 'data/arabian_nights/108.txt',\n",
        " 'data/arabian_nights/109.txt',\n",
        " 'data/arabian_nights/11.txt',\n",
        " 'data/arabian_nights/110.txt',\n",
        " 'data/arabian_nights/111.txt',\n",
        " 'data/arabian_nights/112.txt',\n",
        " 'data/arabian_nights/113.txt',\n",
        " 'data/arabian_nights/114.txt']"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see the files are sorted by their string name and not by their numbering. To be able to sort the files by their numbers we must remove the extension \".txt\" as well as the directory \"data/arabian_nights\"."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**1)** Write a function `remove_txt` that takes as argument a string and some extension that you want to remove. It should return the string without the extension. Tip: use the function `splitext` from the `os.path` module. Look up the documentation [here](http://docs.python.org/3.3/library/os.path.html#os.path.splitext)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os.path import splitext\n",
      "\n",
      "def remove_ext(filename):\n",
      "    # insert your code here\n",
      "    \n",
      "# these tests should return True if your code is correct\n",
      "print(remove_ext(\"data/arabian_nights/1.txt\") == \"data/arabian_nights/1\")\n",
      "print(remove_ext(\"sunny_picture.jpg\") == \"sunny_picture\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n",
        "True\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**2)** Write a function `remove_dir` that takes as argument a filepath and removes the directory from a filepath. Tip: use the function `basename` from the `os.path` module. Look up the document [here](http://docs.python.org/3.3/library/os.path.html#os.path.basename)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from os.path import basename\n",
      "\n",
      "def remove_dir(filepath):\n",
      "    # insert your code here\n",
      "    \n",
      "# these tests should return True if your code is correct\n",
      "print(remove_dir(\"data/arabian_nights/1.txt\") == \"1.txt\")\n",
      "print(remove_dir(\"/a/kind/of/funny/filepath/file.txt\" == \"file.txt\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**3)** Combine the two functions `remove_ext` and `remove_dir` into one function `get_filename`. This function takes as argument a filepath and returns the name (without the extensions) of the file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_filename(filepath):\n",
      "    #insert your code here\n",
      "    \n",
      "# these tests should return True if your code is correct\n",
      "print(get_filename(\"data/arabian_nights/1.txt\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The second step is to convert the strings (e.g. \"1\" and \"10\") to a number. This can be achieved by using the function `int`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x_as_string = \"1\"\n",
      "x_as_int = int(x_as_string)\n",
      "print(x_as_int)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The process of converting a string into an integer, is called `type casting`. Strings are different types than integers. To see this, have a look at the following:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = \"1\"\n",
      "y = \"2\"\n",
      "print(x + y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "12? Yes, 12. This is because, as you might remember from the first chapter, we can use the `+` operator to concatenate two strings. If we apply the same operation to integers, as in:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = 1\n",
      "y = 2\n",
      "print(x + y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "we get the expected result of 3. We can combine the two functions to obtain an number corresponding to each night:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(int(remove_ext(\"1.txt\", \".txt\")))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The suspense created by Shahrazad\u2019s story-telling skills is intriguing, especially the \u201ccliff-hanger\u201d ending each night wich she uses to avert her own execution (and possibly that of womanhood). Every night she tells the Sultan a story only to stop at dawn and she picks up the thread the next night. But does it really take the whole night to tell a particular story?\n",
      "\n",
      "I am not aware of any exact numbers about how many words people speak per minute. Averages seem to fluctuate between 100 and 200 words per minute. Narrators are advised to use approximately 150 words per minute in audiobooks. I suspect that this number is a little lower for live storytelling and assume it lies around 130 words per minute (including pauses). Using this information, we can compute the time it takes to tell a particular story as follows:\n",
      "\n",
      "$$\\textrm{story time}(\\textrm{text}) = \\frac{\\textrm{number of words in text}}{\\textrm{number of words per minute}}$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# story time formula"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plotting the result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> Then Shahrazad reached the morning, and fell silent in the telling of her tale\u2026"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ignore the following, it's just here to make the page pretty:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"styles/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
        "    }\n",
        "    div.cell {\n",
        "        width:800px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    div.cell, .input.hbox {\n",
        "    display:block;\n",
        "}\n",
        "    h1 {\n",
        "        font-family: \"Charis SIL\", Palatino, serif;\n",
        "    }\n",
        "    h4{\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "    div.text_cell_render{\n",
        "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 145%;\n",
        "        font-size: 120%;\n",
        "        width:800px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
        "    }\n",
        "    .prompt{\n",
        "        display: None;\n",
        "    }\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 16pt;\n",
        "        color: #4057A1;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    \n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }\n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "<IPython.core.display.HTML at 0x107a69590>"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "by Folgert Karsdorp (Meertens Instituut) en Maarten van Gompel (Radboud University Nijmegen)\n",
      "\n",
      "Licensed under the [GNU Free Documentation License](http://www.gnu.org/copyleft/fdl.html)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}