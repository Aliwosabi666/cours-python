{
 "metadata": {
  "name": "Authorship attribution"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Chapter 5: Building NLP applications"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the last chapter we made some tools to prepare corpora for further processing. To be able to tokenise a text is nice, but from a humanities perspective not very interesting. So, what are we going to do with it? In this chapter, you'll implement two major applications that build upon the tools you developed. The first will be a program that scores each text in a corpus according to its Automatic Readability Index. In the second application we will build a system that can predict who wrote a certain text. Again, we'll need to cover a lot of ground. So, let's get started!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Automatic Readability Index"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Automatic Readability Index is a readability test designed to gauge the understandability of a text. The formula for calculating the Automated Readability Index is as follows:\n",
      "\n",
      "$$ 4.71 \\cdot \\frac{nchars}{nwords} + 0.5 \\cdot \\frac{nwords}{nsentences} - 21.43 $$\n",
      "\n",
      "Let's apply some wishful thinking. If we have all the information needed to compute this formula, we can start with writing a function that does it for us. Let's do so."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "--------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write a function `AutomaticReadabilityIndex` that takes three arguments `n_chars`, `n_words` and `n-sents` and returns the ARI given those arguments."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def AutomaticReadabilityIndex(n_chars, n_words, n_sents):\n",
      "    # insert your code here\n",
      "\n",
      "print('%.3f' % AutomaticReadabilityIndex(300, 40, 10) == '15.895')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we need to write some code to obtain the numbers we so wishfully assumed to have. We will use the code we wrote in earlier chapters to read and tokenise texts. We stored all the functions we wrote for our corpus reader in `preprocess.py`. We only need the function `readcorpus` and import it here."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from preprocess import readcorpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Remember that the function readcorpus returns a generator of `(filename, sentences)` tuples. Sentences are represented by lists of strings. Let's write a function `extract_counts` that takes a list of sentences as input and returns the number of characters, the number of words and the number of sentences as a tuple."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "----------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write the function `extract_counts`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_counts(sentences):\n",
      "    # insert your code here\n",
      "    \n",
      "print(extract_counts(\n",
      "    [[\"This\", \"was\", \"rather\", \"easy\", \".\"], \n",
      "     [\"Please\", \"give\", \"me\", \"something\", \"more\", \"challenging\"]]) == (54, 11, 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Well done! We're almost done. We could use our two functions to compute the ARI for a given text as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentences = [[\"This\", \"was\", \"rather\", \"easy\", \".\"], \n",
      "             [\"Please\", \"give\", \"me\", \"something\", \"more\", \"challenging\"]]\n",
      "\n",
      "n_chars, n_words, n_sents = extract_counts(sentences)\n",
      "\n",
      "print(\"%.3f\" % AutomaticReadabilityIndex(n_chars, n_words, n_sents) == \"4.442\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, it would be nice to have a little more abstraction."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write the function `compute_ARI` that takes a argument a list of sentences (represented by lists of words) and returns the Automatic Readability Index for that input."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compute_ARI(sentences):\n",
      "    # insert your code here\n",
      "    \n",
      "print(\"%.3f\" % compute_ARI(sentences) == \"4.442\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndentationError",
       "evalue": "expected an indented block (<ipython-input-1-8b6a023ee164>, line 4)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "--------------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Authorship attribution\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this section you will implement the core of a authorship attribution application. You won't build a full stand-alone application, but rather focus on the core functions for classifying new texts for their authors.\n",
      "\n",
      "The core of our application will be a naive bayes classifier. Following good programming principles, we will try to make this classifier as generic as possible. This allows us to use the classifier in other contexts than authorship attribution, such as text classification and classification in general."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The naive bayes classifier is a probabilistic classifier that given a set of features tries to find the class with the highest probability. It is based on applying Bayes' theorem and is called naive because of its strong independence assumption between features. This means that the absence or presence of each feature is assumed to be independent of each other. We compute the posterior probability of a class as the joint probability of all features given that class:\n",
      "\n",
      "$$ P(y|x_1,\\ldots,x_n) \\propto P(y) \\prod^n_{i=1} P(x_i|y)$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Classification is based on the *maximum a posteriori* or MAP descision rule which simply picks the class (or author in our case) that is most probable:\n",
      "\n",
      "$$ classify(x_1, \\ldots, x_n) = \\arg\\max_y P(y) \\prod^n_{i=1} P(x_i|y) $$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The main function we will implement has a simple job: take a text as an argument and classify it as being written by one of the authors. Let's again apply some wishful thinking and implement the function as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def predict_author(text, training_data):\n",
      "    \"Predict who wrote this text.\"\n",
      "    return classify(score(extract_features(text), training_data))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This function takes two arguments: the text to classify and the training data against we want to classify the text. The function is basically an abstraction layer on top of `classify`,  `extract_features` and `score`. `classify` is a simple function that takes a dictionary of {$author_i$:  $P(author_i|text)$} and returns the author that is most probable. Let's implement this function."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "-----------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Implement the function `classify`. It takes one argument, `scores` which is a dictionary with authors as keys and the probability of an author as value. Return the author with maximum probability. (Tip: use the built in function `max`, see [the documentation](http://docs.python.org/2/library/functions.html#max))"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = {\"Hermans\": 0.15, \"Voskuil\": 0.55, \"Reve\": 0.2, \"Mulisch\": 0.18, \"Claus\": 0.02}\n",
      "\n",
      "def classify(scores):\n",
      "    # insert your code here\n",
      "    \n",
      "print(classify(scores) == \"Voskuil\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The function `extract_features` is rather straightforward as well. We'll build this function on top of the functions we defined in the previous chapters. For the moment we will assume that our model is a bag-of-words (BOW) model where the only features are individual words. We will define extract_features as a abstraction layer on top of `readcorpusfile` and `tokenise` as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from preprocess import readcorpusfile, tokenise\n",
      "\n",
      "def extract_features(filename):\n",
      "    return tokenise(readcorpusfile(filename))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now for our training data, we need to store for each word how often it occurs with a particular author. As our data structure we will use a nested dictionary of the following structure `word -> author -> count`. We'll store the counts in the variable `feature_database`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "\n",
      "feature_database = defaultdict(lambda: defaultdict(int))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---------"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Think about why the `word -> author -> count` structure is a better choice than `author -> word -> count`. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "--------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To fill our `feature_database` we will need a couple of functions. First we need a function that returns the author of a particular text. To make things a little easier, we named our training files with the author's name followed by the title of the book, i.e. `austen-emma.txt`."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "-----"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Quiz!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write a function `extract_author` that takes a filename as input and returns the name of the author."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_author(filename):\n",
      "    # insert your code here\n",
      "    \n",
      "print(extract_author(\"Austen-emma.txt\") == \"Austen\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next we'll need a function, `update_counts`, that takes as argument the name of an author and the words extracted using `extract_features` and adds these to our `feature_database`. The function should return a new updated version of the `feature_database`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from preprocess import tokenise\n",
      "\n",
      "def update_counts(author, text, feature_database):\n",
      "    # insert your code here\n",
      "    return feature_database\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# do not modify the code below, for testing only!\n",
      "feature_database = defaultdict(lambda: defaultdict(int))\n",
      "feature_database = update_counts(\"Anonymous\", \"This was written with a lack of inspiration\", \n",
      "                                 feature_database)\n",
      "print(\"{%s}\" % ', '.join(\"%s: {%s: %s}\" % (word, author, count) for \n",
      "      word, counts in feature_database.items() for author, count in counts.items()) == \n",
      "\"{lack: {Anonymous: 1}, was: {Anonymous: 1}, with: {Anonymous: 1}, a: {Anonymous: 1}, of: {Anonymous: 1}, written: {Anonymous: 1}, This: {Anonymous: 1}}\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "True\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "-------"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally we define a function `add_file_to_database` that takes a filename and the `feature_database` as input, extracts the author from the filename and add the feature counts to the `feature_database`. We define it as follows:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def add_file_to_database(filename, feature_database):\n",
      "    return update_counts(extract_author(filename), extract_features(filename), feature_database)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.core.display import HTML\n",
      "def css_styling():\n",
      "    styles = open(\"styles/custom.css\", \"r\").read()\n",
      "    return HTML(styles)\n",
      "css_styling()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<style>\n",
        "    @font-face {\n",
        "        font-family: \"Computer Modern\";\n",
        "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
        "    }\n",
        "    div.cell{\n",
        "        width:800px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    h1 {\n",
        "        font-family: \"Charis SIL\", Palatino, serif;\n",
        "    }\n",
        "    h4{\n",
        "        margin-top:12px;\n",
        "        margin-bottom: 3px;\n",
        "       }\n",
        "    div.text_cell_render{\n",
        "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
        "        line-height: 145%;\n",
        "        font-size: 120%;\n",
        "        width:800px;\n",
        "        margin-left:auto;\n",
        "        margin-right:auto;\n",
        "    }\n",
        "    .CodeMirror{\n",
        "            font-family: \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
        "    }\n",
        "    .prompt{\n",
        "        display: None;\n",
        "    }\n",
        "    .text_cell_render h5 {\n",
        "        font-weight: 300;\n",
        "        font-size: 16pt;\n",
        "        color: #4057A1;\n",
        "        font-style: italic;\n",
        "        margin-bottom: .5em;\n",
        "        margin-top: 0.5em;\n",
        "        display: block;\n",
        "    }\n",
        "    \n",
        "    .warning{\n",
        "        color: rgb( 240, 20, 20 )\n",
        "        }\n",
        "</style>\n",
        "<script>\n",
        "    MathJax.Hub.Config({\n",
        "                        TeX: {\n",
        "                           extensions: [\"AMSmath.js\"]\n",
        "                           },\n",
        "                tex2jax: {\n",
        "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
        "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
        "                },\n",
        "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
        "                \"HTML-CSS\": {\n",
        "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
        "                }\n",
        "        });\n",
        "</script>"
       ],
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "<IPython.core.display.HTML at 0x104b89590>"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}